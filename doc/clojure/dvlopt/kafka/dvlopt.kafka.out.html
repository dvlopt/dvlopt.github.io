<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>dvlopt.kafka.out documentation</title><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="css/highlight.css" /><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Kafka</span> <span class="project-version">1.0.0-beta1</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>dvlopt</span></div></div></li><li class="depth-2"><a href="dvlopt.kafka.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>kafka</span></div></a></li><li class="depth-3 branch"><a href="dvlopt.kafka.admin.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>admin</span></div></a></li><li class="depth-3 branch"><a href="dvlopt.kafka.in.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>in</span></div></a></li><li class="depth-3 current"><a href="dvlopt.kafka.out.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>out</span></div></a></li><li class="depth-2"><a href="dvlopt.kstreams.html"><div class="inner"><span class="tree" style="top: -114px;"><span class="top" style="height: 123px;"></span><span class="bottom"></span></span><span>kstreams</span></div></a></li><li class="depth-3 branch"><a href="dvlopt.kstreams.builder.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>builder</span></div></a></li><li class="depth-3 branch"><a href="dvlopt.kstreams.ctx.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>ctx</span></div></a></li><li class="depth-3 branch"><a href="dvlopt.kstreams.store.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>store</span></div></a></li><li class="depth-3 branch"><a href="dvlopt.kstreams.stream.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>stream</span></div></a></li><li class="depth-3 branch"><a href="dvlopt.kstreams.table.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>table</span></div></a></li><li class="depth-3"><a href="dvlopt.kstreams.topology.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>topology</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="dvlopt.kafka.out.html#var-close"><div class="inner"><span>close</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-flush"><div class="inner"><span>flush</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-metrics"><div class="inner"><span>metrics</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-partitions"><div class="inner"><span>partitions</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-producer"><div class="inner"><span>producer</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-send"><div class="inner"><span>send</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-trx-abort"><div class="inner"><span>trx-abort</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-trx-begin"><div class="inner"><span>trx-begin</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-trx-commit"><div class="inner"><span>trx-commit</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-trx-init"><div class="inner"><span>trx-init</span></div></a></li><li class="depth-1"><a href="dvlopt.kafka.out.html#var-trx-offsets"><div class="inner"><span>trx-offsets</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">dvlopt.kafka.out</h1><div class="doc"><pre class="plaintext">Kafka producers.
</pre></div><div class="public anchor" id="var-close"><h3>close</h3><div class="usage"><code>(close producer)</code><code>(close producer options)</code></div><div class="doc"><pre class="plaintext">Closes the producer and releases all associated resources.

A map of options may be given :

  :dvlopt.kafka/timeout
   Blocks until all requests finish or the given timeout is reached, failing unsent and unacked records immediately.
   Cf. `dvlopt.kafka` for description of time intervals</pre></div></div><div class="public anchor" id="var-flush"><h3>flush</h3><div class="usage"><code>(flush producer)</code></div><div class="doc"><pre class="plaintext">Flushes the producer.

Sends all buffered messages immediately, even if "linger.ms" (producer configuration) is greater than 0, and blocks
until completion. Other threads can continue sending messages but no garantee is made they will be part of the current
flush.</pre></div></div><div class="public anchor" id="var-metrics"><h3>metrics</h3><div class="usage"><code>(metrics producer)</code></div><div class="doc"><pre class="plaintext">Requests metrics about this producer.

Returns a map of metric group name -&gt; (map of metric name -&gt; map) containing :

  :dvlopt.kafka/description (when available)
   String description for human consumption.

  :dvlopt.kafka/properties
   Map of keywords to strings, additional arbitrary key-values.

  :dvlopt.kafka/floating-value
   Numerical value.</pre></div></div><div class="public anchor" id="var-partitions"><h3>partitions</h3><div class="usage"><code>(partitions producer topic)</code></div><div class="doc"><pre class="plaintext">Requests a list of partitions for a given topic.

&lt;!&gt; Blocks forever if the topic does not exist and dynamic creation has been disabled.


Returns a list of maps containing :

  :dvlopt.kafka/leader-node (may be absent)
   Cf. `dvlopt.kafka` for descriptions of Kafka nodes.

  :dvlopt.kafka/partition
   Partition number.

  :dvlopt.kafka/replica-nodes
   Cf. `dvlopt.kafka` for descriptions of Kafka nodes.

  :dvlopt.kafka/topic
   Topic name.</pre></div></div><div class="public anchor" id="var-producer"><h3>producer</h3><div class="usage"><code>(producer)</code><code>(producer options)</code></div><div class="doc"><pre class="plaintext">Builds a Kafka producer.

Producers are thread-safe and it is efficient to share one between multiple threads.

A map of options may be given :

  ::configuration
    Map of Kafka producer properties.
    Cf. <a href="https://kafka.apache.org/documentation/#producerconfigs">https://kafka.apache.org/documentation/#producerconfigs</a>

  :dvlopt.kafka/nodes
    List of [host port].

  :dvlopt.kafka/serializer.key
  :dvlopt.kafka/serializer.value
   Cf. `dvlopt.kafka` for description of serializers.


Ex. (producer {::configuration                {"client.id" "my_id"}
               :dvlopt.kafka/nodes            [["some_host" 9092]]
               :dvlopt.kafka/serializer.key   :string
               :dvlopt.kafka/serializer.value (fn [data _metadata]
                                                (some-&gt; data
                                                        nippy/freeze))})</pre></div></div><div class="public anchor" id="var-send"><h3>send</h3><div class="usage"><code>(send producer record)</code><code>(send producer record callback)</code></div><div class="doc"><pre class="plaintext">In normal mode, asynchronously sends a record to Kafka via a producer and calls the optional callback
on acknowledgment or error. The callback needs to accept 2 arguments : an exception in case of failure and
metadata in case of success. It will be executed on the IO thread of the producer, so it should be fast or
pass data to another thread.

This function returns a future when synchronous behaviour is needed. Derefing the future will throw if a failure
occured or it will provide the same metadata passed to the optional callback.

A record is a map containing at least the :dvlopt.kafka/topic and can also hold :

  :dvlopt.kafka/key
  :dvlopt.kafka/partition
  :dvlopt.kafka/timestamp
  :dvlopt.kafka/value

If the partition is missing, it is automatically selected based on the hash of the key.

Metadata is a map containing :dvlopt.kafka/topic and when available :

  :dvlopt.kafka/offset
  :dvlopt.kafka/partition
  :dvlopt.kafka/timestamp

In transactional mode, there is no need for callbacks or checking the futures because a call to `trx-commit` will
throw the exception from the last failed send. When such a failure occurs, the easiest way to deal with it is simply
to restart the transactional producer.


Ex. (send producer
          {:dvlopt.kafka/key   "some-key"
           :dvlopt.kafka/topic "my-topic"
           :dvlopt.kafka/value 42}
          (fn callback [exception meta]
            (when-not exception
              (println :committed meta))))</pre></div></div><div class="public anchor" id="var-trx-abort"><h3>trx-abort</h3><div class="usage"><code>(trx-abort producer)</code></div><div class="doc"><pre class="plaintext">Aborts the ongoing transaction.
</pre></div></div><div class="public anchor" id="var-trx-begin"><h3>trx-begin</h3><div class="usage"><code>(trx-begin producer)</code></div><div class="doc"><pre class="plaintext">Must be called exactly once at the start of each new transaction.

&lt;!&gt; `trx-init` must be called before any transaction. &lt;!&gt;</pre></div></div><div class="public anchor" id="var-trx-commit"><h3>trx-commit</h3><div class="usage"><code>(trx-commit producer)</code></div><div class="doc"><pre class="plaintext">Requests a commit of the ongoing transaction.

A transaction succeeds only if every step succeeds.

If any record commit hit an irrecoverable error, this function will rethrow that exception and the transaction
will not be committed.</pre></div></div><div class="public anchor" id="var-trx-init"><h3>trx-init</h3><div class="usage"><code>(trx-init producer)</code></div><div class="doc"><pre class="plaintext">The producer configuration "transactional.id" needs to be set.

Based on this id, ensures any previous transaction committed by a previous instance is completed or any pending
transaction is aborted. Further more, it prepares the producer for future ones.

This function needs to be called exactly once prior to doing any new transactions.

Of course, brokers need to support transactions.</pre></div></div><div class="public anchor" id="var-trx-offsets"><h3>trx-offsets</h3><div class="usage"><code>(trx-offsets producer consumer-group topic-partition-&gt;offset)</code></div><div class="doc"><pre class="plaintext">Adds offsets for a consumer group id as part of the ongoing transaction.

Very useful for a consume-transform-produce use case.

The consumer polls records without committing its offsets ("enable.auto.commit" must be set to false). After some computation,
while in a transaction, the producer publishes results as well as the offsets (ie. for each topic partition, the offset of the
last processed record + 1). This garantees exacly once semantics.


Ex. ;; commits offset 65 for "some-topic" partition 0

    (trx-offsets producer
                 "my-consumer-group"
                 {["some-topic" 0] 65})</pre></div></div></div></body></html>